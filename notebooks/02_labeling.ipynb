{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10b1a43",
   "metadata": {},
   "source": [
    "# Análisis de Transacciones - Datathon\n",
    "## Unión de Datos Transaccionales y Demográficos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b65ae1",
   "metadata": {},
   "source": [
    "# Revisar si son Recurrentes los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41988be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO PREPARACIÓN DE DATOS CON PANDAS ===\n",
      "Archivos CSV cargados exitosamente.\n",
      "\n",
      "Preprocesamiento y conversión de tipos completados.\n",
      "\n",
      "DataFrame fusionado. Total de filas: 346011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d_mznhv14n19s_4d9_h190840000gn/T/ipykernel_55439/3199455379.py:96: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_merged['edad_transaccion'].fillna(df_merged['edad_transaccion'].median(), inplace=True)\n",
      "/var/folders/rd/d_mznhv14n19s_4d9_h190840000gn/T/ipykernel_55439/3199455379.py:97: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_merged['antiguedad_cliente'].fillna(df_merged['antiguedad_cliente'].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame ordenado por id, comercio, fecha.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d_mznhv14n19s_4d9_h190840000gn/T/ipykernel_55439/3199455379.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_merged['diff_monto_promedio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "/var/folders/rd/d_mznhv14n19s_4d9_h190840000gn/T/ipykernel_55439/3199455379.py:124: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_merged['diff_monto_promedio'].fillna(0, inplace=True) # Rellenar con 0 si no hay promedio previo o es 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingeniería de características completada.\n",
      "Distribución de la variable objetivo 'es_recurrente' (con criterios ajustados):\n",
      "es_recurrente\n",
      "True     0.616995\n",
      "False    0.383005\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Columnas finales seleccionadas y ordenadas.\n",
      "\n",
      "DataFrame guardado exitosamente como '../data/transacciones_para_modelo.parquet'\n",
      "\n",
      "=== INICIANDO FASE DE MODELADO CON SCIKIT-LEARN ===\n",
      "Datos cargados exitosamente desde: ../data/transacciones_para_modelo.parquet\n",
      "Dimensiones del DataFrame: (346011, 17)\n",
      "Primeras filas:\n",
      "                                         id      fecha comercio  \\\n",
      "0  003d9abe467a91847d566cf455bd2d7d6c8f7e75 2022-01-17   AMAZON   \n",
      "1  003d9abe467a91847d566cf455bd2d7d6c8f7e75 2022-01-17   AMAZON   \n",
      "2  003d9abe467a91847d566cf455bd2d7d6c8f7e75 2022-01-17   AMAZON   \n",
      "3  003d9abe467a91847d566cf455bd2d7d6c8f7e75 2022-01-17   AMAZON   \n",
      "4  003d9abe467a91847d566cf455bd2d7d6c8f7e75 2022-01-17   AMAZON   \n",
      "\n",
      "                                giro_comercio tipo_venta  monto  \\\n",
      "0  COMERCIOS ELECTRONICOS (VTAS POR INTERNET)    digital   2.54   \n",
      "1  COMERCIOS ELECTRONICOS (VTAS POR INTERNET)    digital   2.54   \n",
      "2  COMERCIOS ELECTRONICOS (VTAS POR INTERNET)    digital   2.54   \n",
      "3  COMERCIOS ELECTRONICOS (VTAS POR INTERNET)    digital  22.94   \n",
      "4  COMERCIOS ELECTRONICOS (VTAS POR INTERNET)    digital  52.72   \n",
      "\n",
      "   edad_transaccion genero                              tipo_persona  \\\n",
      "0              23.0      M  Persona Fisica Sin Actividad Empresarial   \n",
      "1              23.0      M  Persona Fisica Sin Actividad Empresarial   \n",
      "2              23.0      M  Persona Fisica Sin Actividad Empresarial   \n",
      "3              23.0      M  Persona Fisica Sin Actividad Empresarial   \n",
      "4              23.0      M  Persona Fisica Sin Actividad Empresarial   \n",
      "\n",
      "   antiguedad_cliente  dias_desde_ultima_compra_comercio  \\\n",
      "0            2.075291                               9999   \n",
      "1            2.075291                                  0   \n",
      "2            2.075291                                  0   \n",
      "3            2.075291                                  0   \n",
      "4            2.075291                                  0   \n",
      "\n",
      "   num_transacciones_previas_comercio  monto_promedio_comercio  \\\n",
      "0                                   0                     0.00   \n",
      "1                                   1                     2.54   \n",
      "2                                   2                     2.54   \n",
      "3                                   3                     2.54   \n",
      "4                                   4                     7.64   \n",
      "\n",
      "   std_dias_entre_compras  diff_monto_promedio  monto_similar  es_recurrente  \n",
      "0                     0.0             0.000000           True          False  \n",
      "1                     0.0             0.000000           True          False  \n",
      "2                     0.0             0.000000           True          False  \n",
      "3                     0.0             8.031496          False          False  \n",
      "4                     0.0             5.900524          False          False  \n",
      "\n",
      "--- Análisis Exploratorio Básico de 'es_recurrente' ---\n",
      "Distribución de la variable objetivo 'es_recurrente':\n",
      "es_recurrente\n",
      "True     0.616995\n",
      "False    0.383005\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Información del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346011 entries, 0 to 346010\n",
      "Data columns (total 17 columns):\n",
      " #   Column                              Non-Null Count   Dtype         \n",
      "---  ------                              --------------   -----         \n",
      " 0   id                                  346011 non-null  object        \n",
      " 1   fecha                               346011 non-null  datetime64[ns]\n",
      " 2   comercio                            346011 non-null  object        \n",
      " 3   giro_comercio                       346011 non-null  object        \n",
      " 4   tipo_venta                          346011 non-null  object        \n",
      " 5   monto                               346011 non-null  float64       \n",
      " 6   edad_transaccion                    346011 non-null  float64       \n",
      " 7   genero                              346011 non-null  object        \n",
      " 8   tipo_persona                        346011 non-null  object        \n",
      " 9   antiguedad_cliente                  346011 non-null  float64       \n",
      " 10  dias_desde_ultima_compra_comercio   346011 non-null  int64         \n",
      " 11  num_transacciones_previas_comercio  346011 non-null  int64         \n",
      " 12  monto_promedio_comercio             346011 non-null  float64       \n",
      " 13  std_dias_entre_compras              346011 non-null  float64       \n",
      " 14  diff_monto_promedio                 346011 non-null  float64       \n",
      " 15  monto_similar                       346011 non-null  bool          \n",
      " 16  es_recurrente                       346011 non-null  bool          \n",
      "dtypes: bool(2), datetime64[ns](1), float64(6), int64(2), object(6)\n",
      "memory usage: 40.3+ MB\n",
      "\n",
      "--- Preparación de Datos para el Modelo ---\n",
      "Dimensiones de X (features): (346011, 14)\n",
      "Dimensiones de y (target): (346011,)\n",
      "\n",
      "Características numéricas identificadas: ['monto', 'edad_transaccion', 'antiguedad_cliente', 'dias_desde_ultima_compra_comercio', 'num_transacciones_previas_comercio', 'monto_promedio_comercio', 'std_dias_entre_compras', 'diff_monto_promedio']\n",
      "Características categóricas identificadas: ['comercio', 'giro_comercio', 'tipo_venta', 'genero', 'tipo_persona', 'monto_similar']\n",
      "\n",
      "Dimensiones de X_train: (259508, 14), y_train: (259508,)\n",
      "Dimensiones de X_test: (86503, 14), y_test: (86503,)\n",
      "Proporción de 'es_recurrente' en y_train:\n",
      "es_recurrente\n",
      "1    0.616994\n",
      "0    0.383006\n",
      "Name: proportion, dtype: float64\n",
      "Proporción de 'es_recurrente' en y_test:\n",
      "es_recurrente\n",
      "1    0.616996\n",
      "0    0.383004\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Entrenando el Modelo Random Forest para Recurrencia ---\n",
      "Modelo entrenado exitosamente.\n",
      "Modelo de recurrencia guardado exitosamente.\n",
      "\n",
      "--- Evaluación del Modelo en el Conjunto de Prueba ---\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     33131\n",
      "           1       0.93      0.99      0.96     53372\n",
      "\n",
      "    accuracy                           0.95     86503\n",
      "   macro avg       0.96      0.94      0.95     86503\n",
      "weighted avg       0.96      0.95      0.95     86503\n",
      "\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[29335  3796]\n",
      " [  273 53099]]\n",
      "\n",
      "AUC-ROC Score: 0.9953\n",
      "\n",
      "--- Importancia de las Características del Modelo ---\n",
      "1. dias_desde_ultima_compra_comercio: 0.5008\n",
      "2. num_transacciones_previas_comercio: 0.1684\n",
      "3. std_dias_entre_compras: 0.1331\n",
      "4. monto_promedio_comercio: 0.0786\n",
      "5. diff_monto_promedio: 0.0233\n",
      "6. comercio_OXXO: 0.0086\n",
      "7. comercio_UBER: 0.0064\n",
      "8. giro_comercio_SERV GUBERNAM, AGUA, ELECTRICIDAD,PREDIAL,TENENCIA: 0.0062\n",
      "9. giro_comercio_TIENDAS DE CONVENIENCIA, MINISUPER: 0.0054\n",
      "10. monto_similar_True: 0.0051\n",
      "11. monto: 0.0048\n",
      "12. comercio_SPOTIFY: 0.0043\n",
      "13. giro_comercio_CASINOS CASAS DE JUEGO (APUESTAS INCLUYE BILLETES): 0.0041\n",
      "14. comercio_CFE: 0.0038\n",
      "15. monto_similar_False: 0.0036\n",
      "\n",
      "--- Próximos Pasos Sugeridos para Predecir CUÁNTO y CUÁNDO ---\n",
      "1. **Re-evaluar el Modelo Clasificador**: Con esta nueva definición, las métricas serán más realistas y el modelo aprenderá de forma más robusta.\n",
      "2. **Identificar Transacciones Recurrentes**: Usa el modelo clasificador para predecir 'es_recurrente' en nuevos datos.\n",
      "3. **Preparar Datos para Modelos de Regresión**: Filtra tu DataFrame original para incluir SOLO las transacciones que el clasificador identificó como recurrentes.\n",
      "4. **Ingeniería de Características para Regresión**: Crea features específicas para predecir monto y fecha (ej. tendencias de monto, estacionalidad, etc.).\n",
      "5. **Modelo de Regresión para 'Monto'**: Entrena un modelo (ej. RandomForestRegressor, LightGBM Regressor) para predecir el 'monto' de la próxima transacción recurrente.\n",
      "6. **Modelo de Regresión/Series de Tiempo para 'Cuándo'**: Entrena un modelo para predecir la 'fecha' o 'días hasta la próxima transacción recurrente'. Esto podría ser más complejo, quizás usando modelos de series de tiempo o regresores que predigan un intervalo.\n",
      "7. **Iteración**: Refina tus modelos, ajusta hiperparámetros y busca más características para mejorar la precisión.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 0. Definir Rutas ---\n",
    "PATH_TX = Path(\"../backend/data/transactions_clean.csv\")          # Transacciones limpias (desde script Polars)\n",
    "PATH_CLI = Path(\"../backend/data/base_clientes_final.csv\")         # Clientes\n",
    "PATH_OUT = Path(\"../backend/data/transacciones_para_modelo.parquet\") # Salida para el modelo\n",
    "\n",
    "# --- Funciones Auxiliares ---\n",
    "def calculate_age_at_transaction(birth_date, transaction_date):\n",
    "    \"\"\"\n",
    "    Calcula la edad (en años) en el momento de la transacción.\n",
    "    \"\"\"\n",
    "    if pd.isna(birth_date) or pd.isna(transaction_date):\n",
    "        return None\n",
    "    if birth_date > transaction_date:\n",
    "        return 0 # Handle anomaly: birth_date in future\n",
    "    age = transaction_date.year - birth_date.year - \\\n",
    "          ((transaction_date.month, transaction_date.day) < (birth_date.month, birth_date.day))\n",
    "    return age\n",
    "\n",
    "def calculate_customer_seniority_at_transaction(signup_date, transaction_date):\n",
    "    \"\"\"\n",
    "    Calcula la antigüedad del cliente (en años) en el momento de la transacción.\n",
    "    \"\"\"\n",
    "    if pd.isna(signup_date) or pd.isna(transaction_date):\n",
    "        return None\n",
    "    if signup_date > transaction_date:\n",
    "        return 0 # Handle anomaly: signup_date in future\n",
    "    seniority_days = (transaction_date - signup_date).days\n",
    "    return seniority_days / 365.25\n",
    "\n",
    "def main_data_preparation():\n",
    "    print(\"=== INICIANDO PREPARACIÓN DE DATOS CON PANDAS ===\")\n",
    "\n",
    "    # --- 1. Cargar los datos ---\n",
    "    try:\n",
    "        df_clientes = pd.read_csv(PATH_CLI)\n",
    "        df_transacciones = pd.read_csv(PATH_TX)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: No se encontró el archivo {e.filename}. Verifica las rutas: \\nClientes: {PATH_CLI}\\nTransacciones: {PATH_TX}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al cargar los archivos CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Archivos CSV cargados exitosamente.\")\n",
    "\n",
    "    # --- 2. Preprocesamiento y Conversión de Tipos ---\n",
    "    # Clientes\n",
    "    df_clientes['fecha_nacimiento'] = pd.to_datetime(df_clientes['fecha_nacimiento'], errors='coerce')\n",
    "    df_clientes['fecha_alta'] = pd.to_datetime(df_clientes['fecha_alta'], errors='coerce')\n",
    "    df_clientes['id'] = df_clientes['id'].astype(str)\n",
    "    df_clientes['genero'] = df_clientes['genero'].fillna('Desconocido')\n",
    "    df_clientes['tipo_persona'] = df_clientes['tipo_persona'].fillna('Desconocido')\n",
    "\n",
    "    # Transacciones\n",
    "    df_transacciones['fecha'] = pd.to_datetime(df_transacciones['fecha'], errors='coerce')\n",
    "    df_transacciones['id'] = df_transacciones['id'].astype(str)\n",
    "    df_transacciones['monto'] = pd.to_numeric(df_transacciones['monto'], errors='coerce')\n",
    "\n",
    "    df_clientes.dropna(subset=['id', 'fecha_nacimiento', 'fecha_alta'], inplace=True)\n",
    "    df_transacciones.dropna(subset=['id', 'fecha', 'monto'], inplace=True)\n",
    "\n",
    "    print(\"\\nPreprocesamiento y conversión de tipos completados.\")\n",
    "\n",
    "    # --- 3. Unir DataFrames ---\n",
    "    cols_clientes_a_usar = ['id', 'fecha_nacimiento', 'fecha_alta', 'genero', 'tipo_persona']\n",
    "    df_merged = pd.merge(df_transacciones, df_clientes[cols_clientes_a_usar], on='id', how='left')\n",
    "\n",
    "    df_merged.dropna(subset=['fecha_nacimiento', 'fecha_alta'], inplace=True)\n",
    "    if df_merged.empty:\n",
    "        print(\"Error: El DataFrame fusionado está vacío después de eliminar filas sin 'fecha_nacimiento' o 'fecha_alta'.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nDataFrame fusionado. Total de filas: {len(df_merged)}\")\n",
    "\n",
    "    # --- 4. Ingeniería de Características ---\n",
    "    df_merged['edad_transaccion'] = df_merged.apply(\n",
    "        lambda row: calculate_age_at_transaction(row['fecha_nacimiento'], row['fecha']), axis=1\n",
    "    ).astype(float)\n",
    "\n",
    "    df_merged['antiguedad_cliente'] = df_merged.apply(\n",
    "        lambda row: calculate_customer_seniority_at_transaction(row['fecha_alta'], row['fecha']), axis=1\n",
    "    ).astype(float)\n",
    "\n",
    "    # Rellenar NaNs resultantes de funciones calculate si es necesario (ej. si alguna fecha fue NaT)\n",
    "    df_merged['edad_transaccion'].fillna(df_merged['edad_transaccion'].median(), inplace=True)\n",
    "    df_merged['antiguedad_cliente'].fillna(df_merged['antiguedad_cliente'].median(), inplace=True)\n",
    "\n",
    "\n",
    "    # Ordenar los datos para cálculos de recurrencia basados en series temporales por cliente y comercio\n",
    "    df_merged.sort_values(['id', 'comercio', 'fecha'], inplace=True)\n",
    "    print(\"\\nDataFrame ordenado por id, comercio, fecha.\")\n",
    "\n",
    "    # Características de recurrencia (usando shift y expanding para evitar look-ahead bias)\n",
    "    # `dias_desde_ultima_compra_comercio`\n",
    "    df_merged['lag_fecha_comercio'] = df_merged.groupby(['id', 'comercio'])['fecha'].shift(1)\n",
    "    df_merged['dias_desde_ultima_compra_comercio'] = (df_merged['fecha'] - df_merged['lag_fecha_comercio']).dt.days.fillna(9999).astype(int) # Usar un valor grande para la primera compra\n",
    "\n",
    "    # `num_transacciones_previas_comercio`\n",
    "    df_merged['num_transacciones_previas_comercio'] = df_merged.groupby(['id', 'comercio']).cumcount()\n",
    "\n",
    "    # `monto_promedio_comercio` (promedio de montos de transacciones *previas* en el mismo comercio)\n",
    "    df_merged['monto_promedio_comercio'] = df_merged.groupby(['id', 'comercio'])['monto'].transform(lambda x: x.expanding().mean().shift(1)).fillna(0).astype(float)\n",
    "    # ^ Se usa shift(1) en expanding() para asegurar que solo se usan datos *previos*\n",
    "\n",
    "    # `std_dias_entre_compras` (std de los días entre compras *previas* en el mismo comercio)\n",
    "    df_merged['dias_entre_esta_y_anterior_comercio'] = df_merged.groupby(['id', 'comercio'])['fecha'].diff().dt.days\n",
    "    df_merged['std_dias_entre_compras'] = df_merged.groupby(['id', 'comercio'])['dias_entre_esta_y_anterior_comercio'].transform(lambda x: x.expanding().std().shift(1)).fillna(0).astype(float)\n",
    "\n",
    "    # `diff_monto_promedio` (diferencia relativa entre el monto actual y el promedio previo)\n",
    "    df_merged['diff_monto_promedio'] = np.abs(df_merged['monto'] - df_merged['monto_promedio_comercio']) / df_merged['monto_promedio_comercio']\n",
    "    # Manejar división por cero/infinito si monto_promedio_comercio es 0 o NaN\n",
    "    df_merged['diff_monto_promedio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_merged['diff_monto_promedio'].fillna(0, inplace=True) # Rellenar con 0 si no hay promedio previo o es 0\n",
    "\n",
    "    # `monto_similar` (boolean)\n",
    "    df_merged['monto_similar'] = (df_merged['diff_monto_promedio'] <= 0.2).astype(bool)\n",
    "\n",
    "\n",
    "    # --- NUEVA DEFINICIÓN DE 'es_recurrente' (Para que el modelo APRENDA) ---\n",
    "    # La variable objetivo 'es_recurrente' ahora indica si la transacción exhibe\n",
    "    # un patrón de frecuencia y/o consistencia de monto que sugiera recurrencia,\n",
    "    # sin ser una definición perfecta que cause data leakage trivial.\n",
    "    # El modelo Random Forest intentará aprender esta lógica de forma más compleja.\n",
    "\n",
    "    # Inicializa 'es_recurrente' como False\n",
    "    df_merged['es_recurrente'] = False\n",
    "\n",
    "    # Condición principal: No es la primera transacción para ese cliente/comercio\n",
    "    # y hay un patrón de repetición o consistencia.\n",
    "    # Esto es crucial para asegurar que la primera compra NUNCA es recurrente.\n",
    "    base_condition_not_first_purchase = (df_merged['num_transacciones_previas_comercio'] >= 1)\n",
    "\n",
    "    # Regla 1: Frecuencia y consistencia temporal (similar a una suscripción)\n",
    "    # Buscamos transacciones que se repiten en intervalos \"razonables\" y de forma consistente.\n",
    "    condition_frequent_consistent = (\n",
    "        (df_merged['dias_desde_ultima_compra_comercio'].between(1, 45)) & # Entre 1 día y 45 días\n",
    "        (df_merged['std_dias_entre_compras'] <= 15) & # Baja variabilidad en los intervalos de compra\n",
    "        (df_merged['num_transacciones_previas_comercio'] >= 2) # Al menos 2 previas (tercera compra en adelante)\n",
    "    )\n",
    "    df_merged.loc[base_condition_not_first_purchase & condition_frequent_consistent, 'es_recurrente'] = True\n",
    "\n",
    "    # Regla 2: Agregadores o comercios de \"gasto frecuente\" con montos similares\n",
    "    # Esto captura giros donde se espera mucha frecuencia, y el monto es parecido.\n",
    "    GIROS_GASTO_FRECUENTE = [\n",
    "        \"COMERCIOS ELECTRONICOS (VTAS POR INTERNET)\",\n",
    "        \"SERVICIOS DE STREAMING\",\n",
    "        \"TELECOMUNICACIONES\",\n",
    "        \"RESTAURANTES\", # Si consideras restaurantes frecuentes para algunos clientes\n",
    "        \"CAFETERIAS\"\n",
    "    ] # Puedes expandir esta lista con giros que sean recurrentes en tu negocio\n",
    "\n",
    "    condition_giro_frequent_similar_monto = (\n",
    "        df_merged['giro_comercio'].isin(GIROS_GASTO_FRECUENTE) &\n",
    "        (df_merged['dias_desde_ultima_compra_comercio'].between(1, 60)) & # Un rango más amplio de días\n",
    "        (df_merged['monto_similar']) & # El monto es similar al promedio\n",
    "        (df_merged['num_transacciones_previas_comercio'] >= 1) # Ya hubo al menos una previa\n",
    "    )\n",
    "    df_merged.loc[base_condition_not_first_purchase & condition_giro_frequent_similar_monto, 'es_recurrente'] = True\n",
    "\n",
    "    # Regla 3: Compras muy frecuentes, aunque no sean \"suscripciones\" típicas\n",
    "    # Captura patrones donde la gente compra a menudo del mismo lugar (ej. supermercado semanal).\n",
    "    condition_very_frequent = (\n",
    "        (df_merged['dias_desde_ultima_compra_comercio'].between(1, 30)) &\n",
    "        (df_merged['num_transacciones_previas_comercio'] >= 4) # Al menos 5 compras en total\n",
    "    )\n",
    "    df_merged.loc[base_condition_not_first_purchase & condition_very_frequent, 'es_recurrente'] = True\n",
    "\n",
    "    # Asegurarse de que la primera transacción con un comercio nunca sea recurrente\n",
    "    # (aunque base_condition_not_first_purchase ya se encarga de esto)\n",
    "    df_merged.loc[df_merged['num_transacciones_previas_comercio'] == 0, 'es_recurrente'] = False\n",
    "\n",
    "    df_merged['es_recurrente'] = df_merged['es_recurrente'].astype(bool)\n",
    "\n",
    "    print(\"\\nIngeniería de características completada.\")\n",
    "    print(\"Distribución de la variable objetivo 'es_recurrente' (con criterios ajustados):\")\n",
    "    print(df_merged['es_recurrente'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "    # --- 5. Seleccionar y Ordenar Columnas Finales ---\n",
    "    columnas_finales = [\n",
    "        \"id\", \"fecha\", \"comercio\", \"giro_comercio\", \"tipo_venta\", \"monto\",\n",
    "        \"edad_transaccion\", \"genero\", \"tipo_persona\", \"antiguedad_cliente\",\n",
    "        \"dias_desde_ultima_compra_comercio\", \"num_transacciones_previas_comercio\", # Incluida como feature\n",
    "        \"monto_promedio_comercio\", \"std_dias_entre_compras\",\n",
    "        \"diff_monto_promedio\", \"monto_similar\", # Incluir estas como features para el modelo\n",
    "        \"es_recurrente\" # La variable objetivo (con criterios ajustados)\n",
    "    ]\n",
    "\n",
    "    df_final = df_merged[columnas_finales].copy()\n",
    "\n",
    "    # Asegurar los tipos de datos finales\n",
    "    df_final['id'] = df_final['id'].astype(str)\n",
    "    df_final['fecha'] = pd.to_datetime(df_final['fecha'])\n",
    "    df_final['comercio'] = df_final['comercio'].astype(str)\n",
    "    df_final['giro_comercio'] = df_final['giro_comercio'].astype(str)\n",
    "    df_final['tipo_venta'] = df_final['tipo_venta'].astype(str)\n",
    "    df_final['monto'] = df_final['monto'].astype(float)\n",
    "    df_final['edad_transaccion'] = df_final['edad_transaccion'].astype(float)\n",
    "    df_final['genero'] = df_final['genero'].astype(str)\n",
    "    df_final['tipo_persona'] = df_final['tipo_persona'].astype(str)\n",
    "    df_final['antiguedad_cliente'] = df_final['antiguedad_cliente'].astype(float)\n",
    "    df_final['dias_desde_ultima_compra_comercio'] = df_final['dias_desde_ultima_compra_comercio'].astype(int)\n",
    "    df_final['num_transacciones_previas_comercio'] = df_final['num_transacciones_previas_comercio'].astype(int)\n",
    "    df_final['monto_promedio_comercio'] = df_final['monto_promedio_comercio'].astype(float)\n",
    "    df_final['std_dias_entre_compras'] = df_final['std_dias_entre_compras'].astype(float)\n",
    "    df_final['diff_monto_promedio'] = df_final['diff_monto_promedio'].astype(float)\n",
    "    df_final['monto_similar'] = df_final['monto_similar'].astype(bool)\n",
    "    df_final['es_recurrente'] = df_final['es_recurrente'].astype(bool)\n",
    "\n",
    "    print(\"\\nColumnas finales seleccionadas y ordenadas.\")\n",
    "\n",
    "    # --- 6. Guardar como Parquet ---\n",
    "    try:\n",
    "        PATH_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df_final.to_parquet(PATH_OUT, index=False, engine='pyarrow')\n",
    "        print(f\"\\nDataFrame guardado exitosamente como '{PATH_OUT}'\")\n",
    "    except ImportError:\n",
    "        print(\"\\nError: Necesitas instalar 'pyarrow' para guardar en formato Parquet.\")\n",
    "        print(\"Puedes instalarlo con: pip install pyarrow\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcurrió un error al guardar el archivo Parquet: {e}\")\n",
    "\n",
    "    return df_final\n",
    "\n",
    "def main_model():\n",
    "    print(\"\\n=== INICIANDO FASE DE MODELADO CON SCIKIT-LEARN ===\")\n",
    "\n",
    "    df = None\n",
    "    try:\n",
    "        df = pd.read_parquet(PATH_OUT)\n",
    "        print(f\"Datos cargados exitosamente desde: {PATH_OUT}\")\n",
    "        print(f\"Dimensiones del DataFrame: {df.shape}\")\n",
    "        print(\"Primeras filas:\")\n",
    "        print(df.head())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró el archivo en {PATH_OUT}. Asegúrate de que la etapa de preparación de datos se haya ejecutado correctamente.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al cargar el archivo Parquet para el modelo: {e}\")\n",
    "        return\n",
    "\n",
    "    TARGET_COLUMN = 'es_recurrente'\n",
    "\n",
    "    print(f\"\\n--- Análisis Exploratorio Básico de '{TARGET_COLUMN}' ---\")\n",
    "    if TARGET_COLUMN not in df.columns:\n",
    "        print(f\"Error: La columna objetivo '{TARGET_COLUMN}' no se encuentra en el DataFrame.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Distribución de la variable objetivo '{TARGET_COLUMN}':\")\n",
    "    print(df[TARGET_COLUMN].value_counts(normalize=True))\n",
    "\n",
    "    print(\"\\nInformación del DataFrame:\")\n",
    "    df.info()\n",
    "\n",
    "    numerical_cols_with_na = df[df.select_dtypes(include=np.number).columns].isnull().sum()\n",
    "    numerical_cols_with_na = numerical_cols_with_na[numerical_cols_with_na > 0].index.tolist()\n",
    "    if numerical_cols_with_na:\n",
    "        print(f\"\\nDetectados NaNs en columnas numéricas: {numerical_cols_with_na}. Rellenando con la mediana.\")\n",
    "        for col in numerical_cols_with_na:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    categorical_cols_with_na = df[df.select_dtypes(exclude=np.number).columns].isnull().sum()\n",
    "    categorical_cols_with_na = categorical_cols_with_na[categorical_cols_with_na > 0].index.tolist()\n",
    "    if categorical_cols_with_na:\n",
    "        print(f\"\\nDetectados NaNs en columnas categóricas: {categorical_cols_with_na}. Rellenando con la moda.\")\n",
    "        for col in categorical_cols_with_na:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    # --- 8. Selección de Características (Features) y Variable Objetivo (Target) ---\n",
    "    features = [\n",
    "        \"comercio\", \"giro_comercio\", \"tipo_venta\", \"monto\",\n",
    "        \"edad_transaccion\", \"genero\", \"tipo_persona\", \"antiguedad_cliente\",\n",
    "        \"dias_desde_ultima_compra_comercio\", \"num_transacciones_previas_comercio\",\n",
    "        \"monto_promedio_comercio\", \"std_dias_entre_compras\",\n",
    "        \"diff_monto_promedio\", \"monto_similar\"\n",
    "    ]\n",
    "\n",
    "    features = [f for f in features if f in df.columns]\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[TARGET_COLUMN].astype(int)\n",
    "\n",
    "    print(f\"\\n--- Preparación de Datos para el Modelo ---\")\n",
    "    print(f\"Dimensiones de X (features): {X.shape}\")\n",
    "    print(f\"Dimensiones de y (target): {y.shape}\")\n",
    "\n",
    "    # --- 9. Preprocesamiento de Características (para Sklearn Pipeline) ---\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    print(f\"\\nCaracterísticas numéricas identificadas: {numerical_features}\")\n",
    "    print(f\"Características categóricas identificadas: {categorical_features}\")\n",
    "\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # --- 10. División de Datos en Entrenamiento y Prueba ---\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.25, # 25% para prueba, 75% para entrenamiento\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"\\nDimensiones de X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Dimensiones de X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "    print(f\"Proporción de '{TARGET_COLUMN}' en y_train:\\n{y_train.value_counts(normalize=True)}\")\n",
    "    print(f\"Proporción de '{TARGET_COLUMN}' en y_test:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "    # --- 11. Creación y Entrenamiento del Pipeline del Modelo ---\n",
    "    model = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        class_weight='balanced', # Sigue siendo útil dado el desbalance\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=5\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "\n",
    "    print(\"\\n--- Entrenando el Modelo Random Forest para Recurrencia ---\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"Modelo entrenado exitosamente.\")\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(pipeline, 'modelo_recurrencia.pkl')\n",
    "    print(\"Modelo de recurrencia guardado exitosamente.\")\n",
    "\n",
    "    # --- 12. Evaluación del Modelo ---\n",
    "    print(\"\\n--- Evaluación del Modelo en el Conjunto de Prueba ---\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nMatriz de Confusión:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"\\nAUC-ROC Score: {auc_score:.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nNo se pudo calcular AUC-ROC: {e}. Esto puede pasar si solo una clase está presente en y_true.\")\n",
    "\n",
    "    # --- 12.1. Importancia de las Características ---\n",
    "    print(\"\\n--- Importancia de las Características del Modelo ---\")\n",
    "    try:\n",
    "        numerical_feature_names_transformed = numerical_features\n",
    "        # Get feature names after one-hot encoding for categorical features\n",
    "        categorical_feature_names_transformed = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "        all_feature_names = list(numerical_feature_names_transformed) + list(categorical_feature_names_transformed)\n",
    "        importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "        sorted_importances = sorted(zip(importances, all_feature_names), reverse=True)\n",
    "        for i, (imp, name) in enumerate(sorted_importances[:15]): # Mostrar las 15 más importantes\n",
    "            print(f\"{i+1}. {name}: {imp:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo obtener la importancia de las características: {e}\")\n",
    "        print(\"Asegúrate de que 'classifier' es un modelo con attribute 'feature_importances_'.\")\n",
    "\n",
    "\n",
    "    # --- 13. Próximos Pasos para tu Objetivo Final ---\n",
    "    print(\"\\n--- Próximos Pasos Sugeridos para Predecir CUÁNTO y CUÁNDO ---\")\n",
    "    print(\"1. **Re-evaluar el Modelo Clasificador**: Con esta nueva definición, las métricas serán más realistas y el modelo aprenderá de forma más robusta.\")\n",
    "    print(\"2. **Identificar Transacciones Recurrentes**: Usa el modelo clasificador para predecir 'es_recurrente' en nuevos datos.\")\n",
    "    print(\"3. **Preparar Datos para Modelos de Regresión**: Filtra tu DataFrame original para incluir SOLO las transacciones que el clasificador identificó como recurrentes.\")\n",
    "    print(\"4. **Ingeniería de Características para Regresión**: Crea features específicas para predecir monto y fecha (ej. tendencias de monto, estacionalidad, etc.).\")\n",
    "    print(\"5. **Modelo de Regresión para 'Monto'**: Entrena un modelo (ej. RandomForestRegressor, LightGBM Regressor) para predecir el 'monto' de la próxima transacción recurrente.\")\n",
    "    print(\"6. **Modelo de Regresión/Series de Tiempo para 'Cuándo'**: Entrena un modelo para predecir la 'fecha' o 'días hasta la próxima transacción recurrente'. Esto podría ser más complejo, quizás usando modelos de series de tiempo o regresores que predigan un intervalo.\")\n",
    "    print(\"7. **Iteración**: Refina tus modelos, ajusta hiperparámetros y busca más características para mejorar la precisión.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_prepared = main_data_preparation()\n",
    "\n",
    "    if df_prepared is not None:\n",
    "        main_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hey_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
