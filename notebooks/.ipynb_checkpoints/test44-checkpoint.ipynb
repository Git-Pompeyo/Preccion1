{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä An√°lisis de Transacciones - Datathon\n",
    "## Notebook de Limpieza y Visualizaci√≥n de Datos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ 1. Carga Inicial de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Lectura simple manteniendo fechas como texto\n",
    "df = pl.read_csv(\n",
    "    \"../data/base_transacciones_final.csv\",\n",
    "    dtypes={\n",
    "        \"id\": pl.Utf8,\n",
    "        \"comercio\": pl.Utf8,\n",
    "        \"giro_comercio\": pl.Utf8,\n",
    "        \"tipo_venta\": pl.Utf8,\n",
    "        \"monto\": pl.Float64,\n",
    "        \"fecha\": pl.Utf8  # Mantenemos fecha como texto\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 2. Exploraci√≥n Inicial del Dataset\n",
    "\n",
    "### 2.1 Informaci√≥n General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma y tipos\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Dtypes:\", df.dtypes)\n",
    "\n",
    "# Ver primeras filas\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Estad√≠sticas Descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas de monto y conteos √∫nicos\n",
    "stats = df.select([\n",
    "    pl.col(\"monto\").mean().alias(\"monto_mean\"),\n",
    "    pl.col(\"monto\").median().alias(\"monto_median\"),\n",
    "    pl.col(\"monto\").std().alias(\"monto_std\"),\n",
    "    pl.col(\"monto\").min().alias(\"min\"),\n",
    "    pl.col(\"monto\").max().alias(\"max\"),\n",
    "    pl.col(\"id\").n_unique().alias(\"unique_ids\"),\n",
    "    pl.col(\"comercio\").n_unique().alias(\"unique_merchants\")\n",
    "    \n",
    "])\n",
    "print(\"Estad√≠sticas:\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 An√°lisis de Datos Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos faltantes por columna\n",
    "print(\"Datos faltantes por columna:\")\n",
    "print(df.null_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 3. An√°lisis de Duplicados\n",
    "\n",
    "### 3.1 Detecci√≥n de Duplicados Exactos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== AN√ÅLISIS DE DUPLICADOS EXACTOS ===\")\n",
    "total_original = df.height\n",
    "\n",
    "# Verificar duplicados exactos: TODAS las columnas id√©nticas\n",
    "print(\"Verificando duplicados donde TODAS las columnas son id√©nticas...\")\n",
    "\n",
    "# M√©todo robusto: group by todas las columnas\n",
    "conteo_exacto = df.group_by(df.columns).agg(pl.len().alias(\"repeticiones\"))\n",
    "duplicados_exactos = conteo_exacto.filter(pl.col(\"repeticiones\") > 1)\n",
    "\n",
    "# Calcular estad√≠sticas\n",
    "grupos_duplicados = duplicados_exactos.height\n",
    "total_filas_duplicadas = duplicados_exactos.select((pl.col(\"repeticiones\") - 1).sum()).item() if grupos_duplicados > 0 else 0\n",
    "\n",
    "print(f\"Filas originales: {total_original:,}\")\n",
    "print(f\"Grupos de filas EXACTAMENTE id√©nticas: {grupos_duplicados:,}\")\n",
    "print(f\"Total de filas duplicadas exactas: {total_filas_duplicadas:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 An√°lisis de Duplicados por Comercio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grupos_duplicados > 0:\n",
    "    print(\"\\n=== AN√ÅLISIS DE DUPLICADOS POR COMERCIO ===\")\n",
    "    \n",
    "    # Agregar columna de comercio Y giro_comercio a los duplicados exactos y calcular estad√≠sticas\n",
    "    duplicados_por_comercio = (\n",
    "        duplicados_exactos\n",
    "        .select([\n",
    "            pl.col(\"comercio\"),\n",
    "            pl.col(\"giro_comercio\"),\n",
    "            (pl.col(\"repeticiones\") - 1).alias(\"num_duplicados\"),  # Solo contar las copias extra\n",
    "            pl.col(\"id\").alias(\"cliente_id\")\n",
    "        ])\n",
    "        .group_by([\"comercio\", \"giro_comercio\"])\n",
    "        .agg([\n",
    "            pl.col(\"num_duplicados\").sum().alias(\"total_duplicados\"),\n",
    "            pl.col(\"cliente_id\").n_unique().alias(\"clientes_afectados\")\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col(\"total_duplicados\") / total_filas_duplicadas * 100).alias(\"porcentaje_de_duplicados\")\n",
    "        ])\n",
    "        .sort(\"total_duplicados\", descending=True)\n",
    "    )\n",
    "    \n",
    "    # EXPORTAR A CSV\n",
    "    duplicados_por_comercio.write_csv(\"../data/duplicados_por_comercio.csv\")\n",
    "    print(f\"‚úÖ Exportado an√°lisis completo a: ../data/duplicados_por_comercio.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Top Comercios con Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"COMERCIOS CON M√ÅS DUPLICADOS:\")\n",
    "    print(\"(comercio | giro_comercio | duplicados | % del total | clientes afectados)\")\n",
    "    print(f\"Total de comercios con duplicados: {duplicados_por_comercio.height}\")\n",
    "    print(\"\\nPrimeros 20:\")\n",
    "    print(duplicados_por_comercio.head(20))\n",
    "    \n",
    "    # Top 10 comercios problem√°ticos\n",
    "    print(f\"\\n=== TOP 10 COMERCIOS M√ÅS PROBLEM√ÅTICOS ===\")\n",
    "    top_comercios_problematicos = duplicados_por_comercio.head(10)\n",
    "    print(top_comercios_problematicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Estad√≠sticas Resumidas de Comercios Problem√°ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f\"\\n=== ESTAD√çSTICAS DE COMERCIOS PROBLEM√ÅTICOS ===\")\n",
    "    total_comercios_con_duplicados = duplicados_por_comercio.height\n",
    "    comercios_top_5 = duplicados_por_comercio.head(5)\n",
    "    duplicados_top_5 = comercios_top_5.select(\"total_duplicados\").sum().item()\n",
    "    porcentaje_top_5 = (duplicados_top_5 / total_filas_duplicadas) * 100\n",
    "    \n",
    "    print(f\"Comercios con duplicados: {total_comercios_con_duplicados}\")\n",
    "    print(f\"Top 5 comercios representan: {duplicados_top_5:,} duplicados ({porcentaje_top_5:.1f}% del total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Ejemplo de Transacci√≥n Duplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Mostrar UN ejemplo de transacci√≥n duplicada (cualquiera)\n",
    "    print(\"\\n=== EJEMPLO DE TRANSACCI√ìN DUPLICADA ===\")\n",
    "    primer_grupo = duplicados_exactos.head(1)\n",
    "    repeticiones_ejemplo = primer_grupo.select(\"repeticiones\").item()\n",
    "    \n",
    "    # Obtener los valores del primer grupo duplicado\n",
    "    valores_ejemplo = primer_grupo.drop(\"repeticiones\").row(0)\n",
    "    \n",
    "    # Filtrar para mostrar todas las repeticiones de este ejemplo\n",
    "    condiciones = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        condiciones.append(pl.col(col) == valores_ejemplo[i])\n",
    "    \n",
    "    filas_ejemplo = df.filter(pl.all_horizontal(condiciones))\n",
    "    print(f\"Transacci√≥n que aparece {repeticiones_ejemplo} veces:\")\n",
    "    print(filas_ejemplo)\n",
    "    \n",
    "    print(\"\\n=== TOP 10 GRUPOS CON M√ÅS REPETICIONES EXACTAS ===\")\n",
    "    top_duplicados = duplicados_exactos.sort(\"repeticiones\", descending=True).head(10)\n",
    "    print(top_duplicados)\n",
    "\n",
    "else:\n",
    "    print(\"‚úÖ No hay duplicados exactos (todas las columnas id√©nticas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Resumen de Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== RESUMEN ===\")\n",
    "if total_filas_duplicadas > 0:\n",
    "    print(f\"Se encontraron {total_filas_duplicadas:,} filas que son duplicados exactos\")\n",
    "    print(\"‚úÖ Archivo 'duplicados_por_comercio.csv' creado con an√°lisis completo\")\n",
    "    print(\"(No se eliminaron - solo an√°lisis)\")\n",
    "else:\n",
    "    print(\"No hay duplicados exactos para eliminar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 4. Normalizaci√≥n de Nombres de Comercios\n",
    "\n",
    "### 4.1 Definici√≥n de Funci√≥n de Normalizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== NORMALIZACI√ìN DE CASOS ESPEC√çFICOS IDENTIFICADOS ===\")\n",
    "\n",
    "def normalizar_casos_especificos(comercio_raw, giro_comercio):\n",
    "    \"\"\"\n",
    "    Solo normaliza los 3 casos espec√≠ficos identificados donde hay \n",
    "    variaciones del mismo merchant en el mismo giro_comercio\n",
    "    \"\"\"\n",
    "    if comercio_raw is None:\n",
    "        return \"DESCONOCIDO\"\n",
    "    \n",
    "    comercio = str(comercio_raw).upper().strip()\n",
    "    \n",
    "    # Caso 1: 7-Eleven en TIENDAS DE CONVENIENCIA\n",
    "    if (comercio in ['7 ELEVEN', '7ELEVEN'] and \n",
    "        giro_comercio == 'TIENDAS DE CONVENIENCIA, MINISUPER'):\n",
    "        return \"7ELEVEN\"\n",
    "    \n",
    "    # Caso 2: DidiFood en LIMOSINAS (TAXIS)  \n",
    "    if (comercio in ['DIDI FOOD', 'DIDIFOOD'] and \n",
    "        giro_comercio == 'LIMOSINAS, (TAXIS)'):\n",
    "        return \"DIDIFOOD\"\n",
    "    \n",
    "    # Caso 3: DidiFood en COMIDA RAPIDA\n",
    "    if (comercio in ['DIDI FOOD', 'DIDIFOOD'] and \n",
    "        giro_comercio == 'COMIDA RAPIDA'):\n",
    "        return \"DIDIFOOD\"\n",
    "    \n",
    "    # Todo lo dem√°s queda igual\n",
    "    return comercio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Aplicaci√≥n de Normalizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar normalizaci√≥n espec√≠fica\n",
    "df = df.with_columns([\n",
    "    pl.struct([\"comercio\", \"giro_comercio\"])\n",
    "    .map_elements(lambda x: normalizar_casos_especificos(x[\"comercio\"], x[\"giro_comercio\"]), return_dtype=pl.Utf8)\n",
    "    .alias(\"merchant_std\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Verificaci√≥n de Normalizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar exactamente qu√© se normaliz√≥\n",
    "print(\"=== VERIFICACI√ìN DE CASOS NORMALIZADOS ===\")\n",
    "casos_normalizados = df.filter(\n",
    "    pl.col(\"comercio\") != pl.col(\"merchant_std\")\n",
    ").group_by([\"comercio\", \"merchant_std\", \"giro_comercio\"]).agg(pl.len().alias(\"transacciones\"))\n",
    "\n",
    "print(\"Casos que fueron normalizados:\")\n",
    "print(casos_normalizados)\n",
    "\n",
    "# Estad√≠sticas de impacto\n",
    "merchants_antes = df.select(pl.col(\"comercio\").n_unique()).item()\n",
    "merchants_despues = df.select(pl.col(\"merchant_std\").n_unique()).item()\n",
    "reduccion = merchants_antes - merchants_despues\n",
    "\n",
    "print(f\"\\n=== IMPACTO FINAL ===\")\n",
    "print(f\"Merchants √∫nicos antes: {merchants_antes:,}\")\n",
    "print(f\"Merchants √∫nicos despu√©s: {merchants_despues:,}\")\n",
    "print(f\"Reducci√≥n: {reduccion:,} merchants (exactamente 3 casos normalizados)\")\n",
    "\n",
    "print(\"\\n‚úÖ Normalizaci√≥n completada para los 3 casos espec√≠ficos identificados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 5. An√°lisis del Dataset Limpio\n",
    "\n",
    "### 5.1 Carga del Dataset Procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CARGANDO TRANSACTIONS_CLEAN.PARQUET ===\")\n",
    "\n",
    "# Cargar el archivo parquet limpio\n",
    "df_clean = pl.read_parquet(\"../data/transactions_clean.parquet\")\n",
    "\n",
    "print(f\"Dataset cargado exitosamente\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Columnas: {df_clean.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Overview General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== OVERVIEW GENERAL ===\")\n",
    "print(f\"Total transacciones: {df_clean.height:,}\")\n",
    "print(f\"Total clientes √∫nicos: {df_clean.select(pl.col('id').n_unique()).item():,}\")\n",
    "print(f\"Total merchants √∫nicos (original): {df_clean.select(pl.col('comercio').n_unique()).item():,}\")\n",
    "\n",
    "# Verificar si tiene merchant_std\n",
    "if \"merchant_std\" in df_clean.columns:\n",
    "    print(f\"Total merchants √∫nicos (normalizado): {df_clean.select(pl.col('merchant_std').n_unique()).item():,}\")\n",
    "\n",
    "# Rango de fechas\n",
    "print(f\"Fecha m√≠nima: {df_clean.select(pl.col('fecha').min()).item()}\")\n",
    "print(f\"Fecha m√°xima: {df_clean.select(pl.col('fecha').max()).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Informaci√≥n de Tipos de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== TIPOS DE DATOS ===\")\n",
    "for col, dtype in zip(df_clean.columns, df_clean.dtypes):\n",
    "    print(f\"{col}: {dtype}\")\n",
    "\n",
    "# Verificar datos faltantes\n",
    "print(f\"\\n=== DATOS FALTANTES ===\")\n",
    "print(df_clean.null_count())\n",
    "\n",
    "# Primeras 10 filas\n",
    "print(f\"\\n=== PRIMERAS 10 FILAS ===\")\n",
    "print(df_clean.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Estad√≠sticas de Montos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== ESTAD√çSTICAS DE MONTOS ===\")\n",
    "stats_monto = df_clean.select([\n",
    "    pl.col(\"monto\").min().alias(\"min\"),\n",
    "    pl.col(\"monto\").quantile(0.25).alias(\"q25\"),\n",
    "    pl.col(\"monto\").median().alias(\"mediana\"),\n",
    "    pl.col(\"monto\").mean().alias(\"promedio\"),\n",
    "    pl.col(\"monto\").quantile(0.75).alias(\"q75\"),\n",
    "    pl.col(\"monto\").quantile(0.95).alias(\"q95\"),\n",
    "    pl.col(\"monto\").max().alias(\"max\"),\n",
    "    pl.col(\"monto\").std().alias(\"std\")\n",
    "])\n",
    "print(stats_monto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Distribuci√≥n por Tipo de Venta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== DISTRIBUCI√ìN POR TIPO DE VENTA ===\")\n",
    "dist_tipo_venta = df_clean.group_by(\"tipo_venta\").agg([\n",
    "    pl.len().alias(\"transacciones\"),\n",
    "    (pl.len() / df_clean.height * 100).alias(\"porcentaje\")\n",
    "]).sort(\"transacciones\", descending=True)\n",
    "print(dist_tipo_venta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Top 15 Giros Comerciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== TOP 15 GIROS COMERCIALES ===\")\n",
    "top_giros = df_clean.group_by(\"giro_comercio\").agg([\n",
    "    pl.len().alias(\"transacciones\"),\n",
    "    (pl.len() / df_clean.height * 100).alias(\"porcentaje\")\n",
    "]).sort(\"transacciones\", descending=True).head(15)\n",
    "print(top_giros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Top 15 Merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== TOP 15 MERCHANTS ===\")\n",
    "merchant_col = \"merchant_std\" if \"merchant_std\" in df_clean.columns else \"comercio\"\n",
    "top_merchants = df_clean.group_by(merchant_col).agg([\n",
    "    pl.len().alias(\"transacciones\"),\n",
    "    (pl.len() / df_clean.height * 100).alias(\"porcentaje\"),\n",
    "    pl.col(\"monto\").mean().alias(\"monto_promedio\")\n",
    "]).sort(\"transacciones\", descending=True).head(15)\n",
    "print(top_merchants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Distribuci√≥n Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== DISTRIBUCI√ìN TEMPORAL (POR MES) ===\")\n",
    "dist_mensual = df_clean.with_columns([\n",
    "    pl.col(\"fecha\").dt.strftime(\"%Y-%m\").alias(\"a√±o_mes\")\n",
    "]).group_by(\"a√±o_mes\").agg([\n",
    "    pl.len().alias(\"transacciones\"),\n",
    "    pl.col(\"monto\").sum().alias(\"monto_total\")\n",
    "]).sort(\"a√±o_mes\")\n",
    "print(dist_mensual)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset transactions_clean.parquet visualizado completamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 6. Exportaci√≥n del Dataset Limpio\n",
    "\n",
    "### 6.1 Exportar a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== EXPORTANDO DATASET LIMPIO A CSV ===\")\n",
    "\n",
    "# Exportar el dataset limpio a CSV\n",
    "df_clean.write_csv(\"../data/transactions_clean.csv\")\n",
    "\n",
    "print(f\"‚úÖ Dataset exportado exitosamente a: ../data/transactions_clean.csv\")\n",
    "print(f\"   - Total de filas exportadas: {df_clean.height:,}\")\n",
    "print(f\"   - Total de columnas: {len(df_clean.columns)}\")\n",
    "print(f\"   - Tama√±o aproximado: {df_clean.height * len(df_clean.columns) * 50 / 1_000_000:.1f} MB (estimado)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Resumen\n",
    "- **An√°lisis de duplicados**: Identificaci√≥n y exportaci√≥n de comercios problem√°ticos\n",
    "- **Normalizaci√≥n**: 3 casos espec√≠ficos normalizados (7-Eleven, DidiFood)\n",
    "- **Dataset limpio**: An√°lisis completo de transacciones procesadas\n",
    "- **Archivos generados**: \n",
    "  - `duplicados_por_comercio.csv`\n",
    "  - `transactions_clean.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}